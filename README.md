# RAG-vs-CRAG

## Table of Contents
- [RAG-vs-CRAG](#rag-vs-crag)
  - [Table of Contents](#table-of-contents)
  - [Project Title](#project-title)
  - [Project Description](#project-description)
  - [Installation and Usage](#installation-and-usage)
    - [Comparison Between RAG and CRAG](#comparison-between-rag-and-crag)
  - [Approach](#approach)
  - [Conclusion](#conclusion)

## Project Title

In this project, we delve into the comparison between two advanced approaches in the field of Generative AI : Retrieval-Augmented Generation (RAG) and Corrective Retrieval-Augmented Generation (CRAG). Both methodologies leverage external knowledge sources to enhance the generation of more accurate and contextually relevant responses. However, they differ in their mechanisms and effectiveness in various applications.

## Project Description

This project aims to provide a detailed analysis of RAG and CRAG, highlighting their key differences, advantages, and potential use cases. We will explore:

- The fundamental difference between RAG and CRAG
- Comparative performance
- Practical implementation details

By the end of this project, we hope to offer insights into which method may be more suitable for specific scenarios and how these technologies can be further developed to improve NLP systems.

## Installation and Usage

How you can run this system in your local machine is described below:

- Clone this repo
- Create a virtual env with `Python >= 3.10.0`
- In the terminal, install all the necessary libraries using 
    ```python
    pip install -r requirements.txt
    ```
- Download `ollama` for desktop from [Ollama Official Site](https://ollama.com/)
- Choose an LLM model for your task. I chose `Llama3 8B` (you can choose some other models as well)
- Download the model using `ollama pull <model_identifier>`, for example,
  ```python
  ollama pull llama3
  ```
- 

### Comparison Between RAG and CRAG

## Approach

## Conclusion